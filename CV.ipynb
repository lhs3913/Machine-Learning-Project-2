{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c8e576f",
   "metadata": {},
   "source": [
    "# Midterm Project 2 - Neural Network Speed-Up (Model Implementation Modification)\n",
    "# Group: Luke Sims, Alvin Liu\n",
    "# Task: Computer Vision (VGG + ResNet)\n",
    "# Method Category: Model Implementation Modification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f14b2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# SECTION 1: SETUP\n",
    "# ===============================\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models\n",
    "import time, copy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Check GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Running on device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9a1fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# SECTION 2: DATA PREPARATION\n",
    "# ===============================\n",
    "\n",
    "# NOTE: Replace with actual public URLs (Caltech-256 / Pascal VOC)\n",
    "# Example placeholder: !wget -q -O caltech256.zip \"<download_link>\"\n",
    "# !unzip -q caltech256.zip -d /content/caltech256\n",
    "\n",
    "\n",
    "data_dir = '/content/caltech256' # replace with real dataset path\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "transforms.Resize((224, 224)),\n",
    "transforms.ToTensor(),\n",
    "transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = datasets.FakeData(transform=transform) # Placeholder dataset\n",
    "val_dataset = datasets.FakeData(transform=transform)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912bd5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# SECTION 3: BASELINE MODEL (FP32)\n",
    "# ===============================\n",
    "\n",
    "def build_model(model_name='resnet18', num_classes=10):\n",
    "if model_name == 'resnet18':\n",
    "model = models.resnet18(weights='IMAGENET1K_V1')\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "elif model_name == 'vgg16':\n",
    "model = models.vgg16(weights='IMAGENET1K_V1')\n",
    "model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
    "return model.to(device)\n",
    "\n",
    "\n",
    "def train_model(model, optimizer, criterion, train_loader, use_amp=False, compile_model=False, epochs=5):\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
